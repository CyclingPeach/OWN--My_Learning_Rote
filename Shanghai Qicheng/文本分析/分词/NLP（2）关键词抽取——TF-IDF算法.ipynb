{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "from jieba import analyse as anls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "text = '''理论上，NLP是一种很吸引人的人机交互方式。早期的语言处理系统如SHRDLU，当它们处于一个有限的“积木世界”，运用有限的词汇表会话\n",
    "时，工作得相当好。这使得研究员们对此系统相当乐观，然而，当把这个系统拓展到充满了现实世界的含糊与不确定性的环境中时，他们很快丧失了信心。\n",
    "由于理解（understanding）自然语言，需要关于外在世界的广泛知识以及运用这些知识的能力，自然语言认知，同时也被视为一个人工智能完备\n",
    "（AI-complete）的问题。同时，在自然语言处理中，\"理解\"的定义也变成一个主要的问题。有关理解定义问题的研究已经引发关注。'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**参数介绍：**\n",
    "\n",
    "```text```:待提取的文本内容。\n",
    "\n",
    "```keyword_num```：制定提取的关键词数量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "理论上，NLP是一种很吸引人的人机交互方式。早期的语言处理系统如SHRDLU，当它们处于一个有限的“积木世界”，运用有限的词汇表会话\n",
      "时，工作得相当好。这使得研究员们对此系统相当乐观，然而，当把这个系统拓展到充满了现实世界的含糊与不确定性的环境中时，他们很快丧失了信心。\n",
      "由于理解（understanding）自然语言，需要关于外在世界的广泛知识以及运用这些知识的能力，自然语言认知，同时也被视为一个人工智能完备\n",
      "（AI-complete）的问题。同时，在自然语言处理中，\"理解\"的定义也变成一个主要的问题。有关理解定义问题的研究已经引发关注。\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### TF-IDF算法\n",
    "\n",
    "[TF-IDF及其算法](TF-IDF及其算法)\n",
    "\n",
    "**概念**\n",
    "\n",
    "     TF-IDF（term frequency–inverse document frequency）是一种用于资讯检索与资讯探勘的常用加权技术。TF-IDF是一种统计方法，用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。TF-IDF加权的各种形式常被搜寻引擎应用，作为文件与用户查询之间相关程度的度量或评级。除了TF-IDF以外，因特网上的搜寻引擎还会使用基于连结分析的评级方法，以确定文件在搜寻结果中出现的顺序。\n",
    "\n",
    "**原理**\n",
    "\n",
    "    在一份给定的文件里，词频 (term frequency, TF) 指的是某一个给定的词语在该文件中出现的次数。这个数字通常会被归一化（分子一般小于分母 区别于IDF），以防止它偏向长的文件。（同一个词语在长文件里可能会比短文件有更高的词频，而不管该词语重要与否。）\n",
    "\n",
    "    逆向文件频率 (inverse document frequency, IDF) 是一个词语普遍重要性的度量。某一特定词语的IDF，可以由总文件数目除以包含该词语之文件的数目，再将得到的商取对数得到。\n",
    "\n",
    "**示例**\n",
    "    \n",
    "    词频 (TF) 是一词语出现的次数除以该文件的总词语数。\n",
    "    \n",
    "    假如一篇文件的总词语数是100个，而词语“母牛”出现了3次，那么“母牛”一词在该文件中的词频（TF）就是3/100=0.03。\n",
    "    \n",
    "    在10,000,000份文件中有1,000份文件出现了“母牛”一词, 那么逆向文件频率就是 log(10,000,000 / 1,000)=4\n",
    "    \n",
    "    TF-IDF的分数为0.03*4 = 0.12\n",
    "\n",
    "\n",
    "```jieba.analyse.extract_tags```\n",
    "\n",
    "jieba库中的关键词提取模块，用于TF-IDF算法抽取关键词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def tfidf_extract(text,keyword_num=10):\n",
    "    tfidf = anls.extract_tags    # extract_tags jieba.analyse中的关键词提取模块\n",
    "    path = 'F:\\陶志远\\Jupyter Notebook\\【笔记系列】\\stopword.txt'\n",
    "    anls.set_stop_words(path)    # 将停用词表加载到内存，过滤文本。\n",
    "    keywords = tfidf(text, keyword_num)\n",
    "    # 输出抽取出的关键词\n",
    "    for keyword in keywords:\n",
    "        print(keyword + \"/ \", end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\ZHIYUA~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.851 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "自然语言/ 理解/ 系统/ 定义/ 词汇表/ 世界/ 知识/ 运用/ 有限/ NLP/ "
     ]
    }
   ],
   "source": [
    "tfidf_extract(text, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### TF-IDF算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# TextRank算法\n",
    "def textrank_extract(text,keyword_num=10):\n",
    "    textrank = anls.textrank     # textrank jieba.analyse中的关键词提取模块\n",
    "    path = 'F:\\陶志远\\Jupyter Notebook\\【笔记系列】\\stopword.txt'\n",
    "    anls.set_stop_words(path)  # 将停用词表加载到内存，过滤文本。\n",
    "    keywords = textrank(text, keyword_num)\n",
    "    # 输出抽取出的关键词\n",
    "    for keyword in keywords:\n",
    "        print(keyword + \"/ \", end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "世界/ 问题/ 运用/ 理解/ 知识/ 系统/ 定义/ 研究/ 方式/ 能力/ \n"
     ]
    }
   ],
   "source": [
    "textrank_extract(text,10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
